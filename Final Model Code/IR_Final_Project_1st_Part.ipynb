{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR Final Project-1st Part.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTOCg6JnFTUk",
        "outputId": "773dcf65-8a64-4327-cb3b-85535905760e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGSrNTfAFtWG",
        "outputId": "bbe8b154-37f3-4b98-aa95-76564a2863ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_excel('/content/drive/MyDrive/Annotated_Article_Dataset.xlsx')\n",
        "data=data.dropna()"
      ],
      "metadata": {
        "id": "nw0lxIYCFydc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing the Dataset\n",
        "def Preprocessing(text):\n",
        "\n",
        "  #converting into lower case\n",
        "  text=text.lower()\n",
        "\n",
        "  #lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  new_tokens=[] \n",
        "  #applying lemmatization\n",
        "  for token in tokens:\n",
        "    new_tokens.append(lemmatizer.lemmatize(token))\n",
        "\n",
        "  #Removing stopwords and Punctuation\n",
        "  stop = stopwords.words('english') + list(string.punctuation) + [\"''\",\"``\",\"..\"]\n",
        "  preprocessed = \" \".join(i for i in new_tokens if i not in stop)\n",
        "  return preprocessed\n"
      ],
      "metadata": {
        "id": "qO8z_E9bF2ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(raw_data):\n",
        "  #articles\n",
        "  articles=[]\n",
        "  #label assigned to them\n",
        "  labels=[]\n",
        "  #Iterating through articles & label\n",
        "  for article,label in zip(raw_data.Article.iloc,raw_data.Annotation.iloc):    \n",
        "    article=Preprocessing(article)\n",
        "    articles.append(article)  \n",
        "    labels.append(label.upper())\n",
        "  Tuples = list(zip(articles, labels))  \n",
        "  return pd.DataFrame(Tuples, columns = ['Article', 'label']) \n"
      ],
      "metadata": {
        "id": "k7VrOSN4F8q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=preprocess(data)"
      ],
      "metadata": {
        "id": "dwPg5k2OF_z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score,classification_report,accuracy_score\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df['Article'],df['label'], test_size=0.25,random_state=42,shuffle=True,stratify=df['label'])"
      ],
      "metadata": {
        "id": "68kef1ZyGbdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "#tf idf vectorizer\n",
        "vector=TfidfVectorizer(analyzer='word',ngram_range=(1,1))"
      ],
      "metadata": {
        "id": "0gEXmBNDGCac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=vector.fit_transform(X_train)\n",
        "x_test=vector.transform(X_test)"
      ],
      "metadata": {
        "id": "qJBU95W3GRvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "LnYdDpHyHF_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernels = ['Polynomial', 'RBF', 'Sigmoid','Linear']#A function which returns the corresponding SVC model\n",
        "def getClassifier(ktype):\n",
        "    if ktype == 0:\n",
        "        # Polynomial kernal\n",
        "        return SVC(kernel='poly', degree=8, gamma=\"auto\")\n",
        "    elif ktype == 1:\n",
        "        # Radial Basis Function kernal\n",
        "        return SVC(kernel='rbf', gamma=\"auto\")\n",
        "    elif ktype == 2:\n",
        "        # Sigmoid kernal\n",
        "        return SVC(kernel='sigmoid', gamma=\"auto\")\n",
        "    elif ktype == 3:\n",
        "        # Linear kernal\n",
        "        return SVC(kernel='linear', gamma=\"auto\")"
      ],
      "metadata": {
        "id": "lPj0DK_yHFGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "    svclassifier = getClassifier(i) \n",
        "    svclassifier.fit(x_train, Y_train)# Make prediction\n",
        "    y_pred = svclassifier.predict(x_test)# Evaluate our model\n",
        "    print(\"Evaluation:\", kernels[i], \"kernel\")\n",
        "    print(classification_report(Y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gONpJVIHHKHi",
        "outputId": "67146679-abf7-4a7f-d061-6cb505db4558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation: Polynomial kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AAP       0.00      0.00      0.00        22\n",
            "         BJP       0.00      0.00      0.00        72\n",
            "    CONGRESS       0.00      0.00      0.00        48\n",
            "        NONE       0.37      1.00      0.54        83\n",
            "\n",
            "    accuracy                           0.37       225\n",
            "   macro avg       0.09      0.25      0.13       225\n",
            "weighted avg       0.14      0.37      0.20       225\n",
            "\n",
            "Evaluation: RBF kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AAP       0.00      0.00      0.00        22\n",
            "         BJP       0.00      0.00      0.00        72\n",
            "    CONGRESS       0.00      0.00      0.00        48\n",
            "        NONE       0.37      1.00      0.54        83\n",
            "\n",
            "    accuracy                           0.37       225\n",
            "   macro avg       0.09      0.25      0.13       225\n",
            "weighted avg       0.14      0.37      0.20       225\n",
            "\n",
            "Evaluation: Sigmoid kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AAP       0.00      0.00      0.00        22\n",
            "         BJP       0.00      0.00      0.00        72\n",
            "    CONGRESS       0.00      0.00      0.00        48\n",
            "        NONE       0.37      1.00      0.54        83\n",
            "\n",
            "    accuracy                           0.37       225\n",
            "   macro avg       0.09      0.25      0.13       225\n",
            "weighted avg       0.14      0.37      0.20       225\n",
            "\n",
            "Evaluation: Linear kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AAP       0.96      1.00      0.98        22\n",
            "         BJP       0.73      0.82      0.77        72\n",
            "    CONGRESS       0.72      0.60      0.66        48\n",
            "        NONE       0.84      0.82      0.83        83\n",
            "\n",
            "    accuracy                           0.79       225\n",
            "   macro avg       0.81      0.81      0.81       225\n",
            "weighted avg       0.79      0.79      0.79       225\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classifier Algorithm**"
      ],
      "metadata": {
        "id": "Dvk74afaHZ5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "def run_classifier(clf, param_grid, title):\n",
        "    # -----------------------------------------------------\n",
        "    cv = StratifiedKFold(n_splits= 3, shuffle = True, random_state= 123)\n",
        "    # Randomized grid search\n",
        "    n_iter_search = 10\n",
        "    gs = RandomizedSearchCV(clf, \n",
        "                            param_distributions = param_grid,\n",
        "                            n_iter = n_iter_search, \n",
        "                            cv = cv,                 \n",
        "                            scoring= 'accuracy')\n",
        "    # -----------------------------------------------------\n",
        "    # Train model\n",
        "    gs.fit(x_train, Y_train)  \n",
        "    print(\"The best parameters are %s\" % (gs.best_params_)) \n",
        "    # Predict on test set\n",
        "    y_pred = gs.best_estimator_.predict(x_test)\n",
        "    # Get Probability estimates\n",
        "    y_prob = gs.best_estimator_.predict_proba(x_test)[:, 1]\n",
        "    # -----------------------------------------------------\n",
        "    print('Accuracy score: %.2f%%' %(accuracy_score(Y_test, y_pred)*100))  \n",
        "    print('Precision score: %.2f%%' % (precision_score(Y_test, y_pred, average= 'weighted')*100))\n",
        "    print('Recall score: %.2f%%' % (recall_score(Y_test, y_pred, average= 'weighted')*100))"
      ],
      "metadata": {
        "id": "SUtJDJUPGpeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logisitic Regression**"
      ],
      "metadata": {
        "id": "w1bABG8fHflX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "param_grid = {'penalty': ['l2'],\n",
        "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "run_classifier(lr, param_grid, 'Logistic Regression')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0ed3U6SGzW3",
        "outputId": "f7274b16-ad17-45e6-d872-7a438017a430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'solver': 'saga', 'penalty': 'l2'}\n",
            "Accuracy score: 76.44%\n",
            "Precision score: 77.89%\n",
            "Recall score: 76.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "W716xniCHrzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zqNvuAAYHo7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "param_grid = {'n_neighbors': np.arange(1,15), \n",
        "             'weights': ['uniform', 'distance'],\n",
        "             'leaf_size':[1, 3, 5],\n",
        "             'algorithm':['auto', 'kd_tree']}\n",
        "run_classifier(knn, param_grid, 'Nearest Neighbors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqxBt0XDHkmZ",
        "outputId": "3493fc2b-25e5-4dcc-d009-8a66801c5b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'weights': 'uniform', 'n_neighbors': 14, 'leaf_size': 5, 'algorithm': 'auto'}\n",
            "Accuracy score: 76.44%\n",
            "Precision score: 77.85%\n",
            "Recall score: 76.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "c34KMOA9H1g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree = DecisionTreeClassifier()\n",
        "param_grid = {'criterion': ['gini', 'entropy'],\n",
        "              'splitter': ['best', 'random'],\n",
        "              'max_depth': np.arange(1, 20, 2),\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 2, 4, 10],\n",
        "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
        "run_classifier(dtree, param_grid, \"Decision Tree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD5VJhAkHz1t",
        "outputId": "82735aa0-5926-45e5-94fe-1cc8ea210bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'splitter': 'random', 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 9, 'criterion': 'gini'}\n",
            "Accuracy score: 75.11%\n",
            "Precision score: 75.93%\n",
            "Recall score: 75.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "S8LxosP_IGyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "param_grid = {'n_estimators': [100, 200],\n",
        "              'max_depth': [10, 20, 100, None],\n",
        "              'max_features': ['auto', 'sqrt', None],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 2, 4, 10],\n",
        "              'bootstrap': [True, False],\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "run_classifier(rf, param_grid, 'Random Forest')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5PeithsIKbI",
        "outputId": "0697153f-011a-4716-90cf-59b4bca08f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 100, 'criterion': 'gini', 'bootstrap': True}\n",
            "Accuracy score: 84.89%\n",
            "Precision score: 85.18%\n",
            "Recall score: 84.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest - One Vs All MultiClass Classifier**"
      ],
      "metadata": {
        "id": "yypneWBkIYSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "model =RandomForestClassifier(n_estimators= 200, min_samples_split= 2, min_samples_leaf= 2, max_features= None, max_depth= 100, criterion= 'gini', bootstrap= True)\n",
        "ovr = OneVsRestClassifier(model)\n",
        "ovr.fit(x_train, Y_train)\n",
        "y_pred = ovr.predict(x_test)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "print(\"Confusion Matrix : \\n\", cm)\n",
        "print('Accuracy score: %.2f%%' %(accuracy_score(Y_test, y_pred)*100))  \n",
        "print('Precision score: %.2f%%' % (precision_score(Y_test, y_pred, average= 'weighted')*100))\n",
        "print('Recall score: %.2f%%' % (recall_score(Y_test, y_pred, average= 'weighted')*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb-MPkV-IP32",
        "outputId": "e9ae072f-9b17-49ea-e1d6-4fbbe08b22fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            " [[22  0  0  0]\n",
            " [ 0 67  3  2]\n",
            " [ 0  3 38  7]\n",
            " [ 1  8  3 71]]\n",
            "Accuracy score: 88.00%\n",
            "Precision score: 88.00%\n",
            "Recall score: 88.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = '/content/drive/MyDrive/IR PROJECT/RFC_SplitDataset.sav'\n",
        "pickle.dump(ovr, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "iZtAx4cDNRIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest - One Vs One MultiClass Classifier**"
      ],
      "metadata": {
        "id": "MoRyAdnbJ-I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "model =RandomForestClassifier(n_estimators= 200, min_samples_split= 2, min_samples_leaf= 2, max_features= None, max_depth= 100, criterion= 'gini', bootstrap= True)\n",
        "ovo = OneVsOneClassifier(model)\n",
        "ovo.fit(x_train, Y_train)\n",
        "y_pred = ovo.predict(x_test)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "print(\"Confusion Matrix : \\n\", cm)\n",
        "print('Accuracy score: %.2f%%' %(accuracy_score(Y_test, y_pred)*100))  \n",
        "print('Precision score: %.2f%%' % (precision_score(Y_test, y_pred, average= 'weighted')*100))\n",
        "print('Recall score: %.2f%%' % (recall_score(Y_test, y_pred, average= 'weighted')*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3S7DGARKFWq",
        "outputId": "75e1b66e-5177-4f13-99f9-bbee3beb7e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            " [[21  0  0  1]\n",
            " [ 0 53  8 11]\n",
            " [ 0  5 39  4]\n",
            " [ 0  8  2 73]]\n",
            "Accuracy score: 82.67%\n",
            "Precision score: 82.71%\n",
            "Recall score: 82.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dumping the Model**"
      ],
      "metadata": {
        "id": "uJQayDdbJSxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df['Article']\n",
        "Y=df['label']\n",
        "X=vector.fit_transform(X)"
      ],
      "metadata": {
        "id": "ShEusprxKWcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ovr.fit(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9xbxdYLI2W",
        "outputId": "e05ccfbf-b1af-4688-88de-54a6413f87ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=100,\n",
              "                                                     max_features=None,\n",
              "                                                     min_samples_leaf=2,\n",
              "                                                     n_estimators=200))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = '/content/drive/MyDrive/IR PROJECT/TrainingDataset.sav'\n",
        "pickle.dump(X, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "fnEbrx7eLlF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = '/content/drive/MyDrive/IR PROJECT/RFC_Dataset.sav'\n",
        "pickle.dump(ovr, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "xN30tJeZLS-d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}