{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR Final Project-2nd Part.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTOCg6JnFTUk",
        "outputId": "84a08ab8-bbc5-4215-d0ab-39d610380469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGSrNTfAFtWG",
        "outputId": "a03dac37-c574-4b27-fbe6-1941c7750175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_excel('/content/drive/MyDrive/Annotated_Article_Dataset.xlsx')\n",
        "data=data.dropna()"
      ],
      "metadata": {
        "id": "nw0lxIYCFydc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing the Dataset\n",
        "def Preprocessing(text):\n",
        "\n",
        "  #converting into lower case\n",
        "  text=text.lower()\n",
        "\n",
        "  #lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  new_tokens=[] \n",
        "  #applying lemmatization\n",
        "  for token in tokens:\n",
        "    new_tokens.append(lemmatizer.lemmatize(token))\n",
        "\n",
        "  #Removing stopwords and Punctuation\n",
        "  stop = stopwords.words('english') + list(string.punctuation) + [\"''\",\"``\",\"..\"]\n",
        "  preprocessed = \" \".join(i for i in new_tokens if i not in stop)\n",
        "  return preprocessed\n"
      ],
      "metadata": {
        "id": "qO8z_E9bF2ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(raw_data):\n",
        "  #articles\n",
        "  articles=[]\n",
        "  #label assigned to them\n",
        "  labels=[]\n",
        "  #Iterating through articles & label\n",
        "  for article,label in zip(raw_data.Article.iloc,raw_data.Annotation.iloc):    \n",
        "    article=Preprocessing(article)\n",
        "    articles.append(article)  \n",
        "    labels.append(label.upper())\n",
        "  Tuples = list(zip(articles, labels))  \n",
        "  return pd.DataFrame(Tuples, columns = ['Article', 'label']) \n"
      ],
      "metadata": {
        "id": "k7VrOSN4F8q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=preprocess(data)"
      ],
      "metadata": {
        "id": "dwPg5k2OF_z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score,classification_report,accuracy_score\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df['Article'],df['label'], test_size=0.25,random_state=42,shuffle=True,stratify=df['label'])"
      ],
      "metadata": {
        "id": "68kef1ZyGbdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection**"
      ],
      "metadata": {
        "id": "ZuwKhCsBNDQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_label={'BJP':0,'CONGRESS':1,'AAP':2,'NONE':3}\n",
        "reverse_class_label={0:'BJP',1:'CONGRESS',2:'AAP',3:'NONE'} \n",
        "def table_creation(X_train,Y_train):\n",
        "  #To keep the track of the Article Count of a term in a particular class\n",
        "  # table dictionary will have class count for each term.\n",
        "  table={}  \n",
        "  #Term count in a class           \n",
        "  term_count={}\n",
        "  #Number of Articles in a Class         \n",
        "  docs_count=np.array([0,0,0,0])\n",
        "  #Number of Words in a Class\n",
        "  words_count=np.array([0,0,0,0])\n",
        "  class_count=np.array([0,0,0,0])\n",
        "\n",
        "  for article,label in zip(X_train,Y_train):\n",
        "    docs_count[class_label[label]]+=1\n",
        "    words_count[class_label[label]]+=len(article)\n",
        "    unique_Tokens={-1}\n",
        "    for term in article.split():\n",
        "      #term count in of each term in each class\n",
        "      if term not in term_count:\n",
        "        term_count[term]=class_count.copy()\n",
        "      term_count[term][class_label[label]]+=1\n",
        "      unique_Tokens.add(term)\n",
        "    \n",
        "    #print(\"unique tokens in article are\",unique_Tokens)\n",
        "    unique_Tokens.remove(-1) \n",
        "\n",
        "    for term in unique_Tokens:\n",
        "      if term not in table:\n",
        "        table[term]=class_count.copy()\n",
        "      table[term][class_label[label]]+=1\n",
        "  \n",
        "  return table, words_count, docs_count, term_count\n",
        "  \n",
        "table, words_count, docs_count, term_count=table_creation(X_train,Y_train)"
      ],
      "metadata": {
        "id": "-rvpvJzXNBEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating Mutual Information for each term in each Class: BJP, AAP, Congress, None(NOT BIASED)\n",
        "def calculating_Mutual_Info(table,words_count,docs_count):\n",
        "  N=0\n",
        "  for i in docs_count:\n",
        "    N+=i\n",
        "  print(\"total number of articles are\",N)\n",
        "  #List to contain the mutual info for each class\n",
        "  mutual_Info_table=[[],[],[],[]] \n",
        "  for term in table:\n",
        "      for class_ in range(0,4):\n",
        "          #Term Present in class\n",
        "          N_11=table[term][class_]  \n",
        "          #Term Present but not in Class\n",
        "          N_10=np.sum(table[term])-N_11 \n",
        "          #Num of Docs in class NOT having term       \n",
        "          N_01=docs_count[class_]-N_11\n",
        "          #Num of Docs neither Term Nor Class\n",
        "          N_00=N-(N_01+N_10+N_11)                \n",
        "          \n",
        "          if N_11==0:\n",
        "              X=0\n",
        "          else:\n",
        "              X=(N_11/N) * ((np.log(N)+np.log(N_11)) - (np.log(N_11+N_01) + np.log(N_11+N_10)))\n",
        "          if N_01==0:\n",
        "              Y=0\n",
        "          else:\n",
        "              Y=(N_01/N) * ((np.log(N)+np.log(N_01)) - (np.log(N_01+N_00) + np.log(N_01+N_11)))\n",
        "          if N_10==0:\n",
        "              Z=0\n",
        "          else:\n",
        "              Z=(N_10/N) * ((np.log(N)+np.log(N_10)) - (np.log(N_10+N_11) + np.log(N_10+N_00)))\n",
        "          if N_00==0:\n",
        "              W=0\n",
        "          else:\n",
        "              W=(N_00/N) * ((np.log(N)+np.log(N_00)) - (np.log(N_00+N_01) + np.log(N_00+N_10)))\n",
        "          m=X+Y+Z+W\n",
        "          mutual_Info_table[class_].append(m)\n",
        "  return mutual_Info_table\n",
        "mutual_Info_table=calculating_Mutual_Info(table,words_count, docs_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlakV1O2NM88",
        "outputId": "27613793-585f-4004-b06f-560b1a043677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of articles are 674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating word map, each word is assigned a uniuqe id like we did for each document\n",
        "def creating_map_of_words(list_of_words):\n",
        "    forward_map={}\n",
        "    reverse_map={}\n",
        "    count=0\n",
        "    for word in list_of_words:\n",
        "        forward_map[word] = count\n",
        "        count = count + 1\n",
        "    reverse_map = {v: k for k, v in forward_map.items()}\n",
        "    return forward_map,reverse_map\n",
        "forward_map,reverse_map=creating_map_of_words(table.keys())\n"
      ],
      "metadata": {
        "id": "e2y8GZgTNjh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this method will select feaures for each class and returns new vocabulary\n",
        "def feature_selection(mutual_Info_table,k,forward_map,reverse_map):\n",
        "    top_k_words=[]\n",
        "    for id in range(0,4):\n",
        "        temp = np.argsort(np.array(mutual_Info_table[id]))\n",
        "        temp = temp[::-1]\n",
        "        top_k_words.append(temp[:k].copy())\n",
        "    \n",
        "    new_vocab={-1}\n",
        "    count=0\n",
        "    for list_of_words in top_k_words:\n",
        "        for wordid in list_of_words:\n",
        "            new_vocab.add(reverse_map[wordid])\n",
        "        count=count+1\n",
        "        \n",
        "    new_vocab.remove(-1)\n",
        "    return top_k_words,new_vocab\n",
        "\n",
        "top_k_words,new_vocab=feature_selection(mutual_Info_table,200,forward_map,reverse_map)\n"
      ],
      "metadata": {
        "id": "L5Y0albqNtuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to calculate term and class probability \n",
        "def calc_prob(new_vocab,term_count,class_word_count,docs_count):\n",
        "    tprobability={}\n",
        "    beta=len(new_vocab)\n",
        "    for word in new_vocab:\n",
        "      tprobability[word]=[]\n",
        "      for id in range(0,4):\n",
        "        tot=class_word_count[id]\n",
        "        tc=term_count[word][id]\n",
        "        p=(tc+1)/(tot+beta)\n",
        "        tprobability[word].append(p)    \n",
        "    cprobability=[]\n",
        "    N=np.sum(docs_count)\n",
        "    for doc_count in docs_count:\n",
        "        cprobability.append(doc_count/N)\n",
        "    return cprobability,tprobability\n",
        "cprobability,tprobability=calc_prob(new_vocab,term_count,words_count,docs_count)"
      ],
      "metadata": {
        "id": "Ny_Dwd-HNww2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "def count_vector(X_data,vocab,term_count):\n",
        "  data_count=[]\n",
        "  for index in X_data:\n",
        "    count_vector=[]\n",
        "    values=index.split(' ')\n",
        "    for word in vocab:\n",
        "      if word in values:\n",
        "        count_vector.append(values.count(word))\n",
        "      else:\n",
        "        count_vector.append(0)\n",
        "    data_count.append(count_vector)\n",
        "  return data_count"
      ],
      "metadata": {
        "id": "u8dRRqGaN0ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=count_vector(X_train,new_vocab,term_count)\n",
        "x_test=count_vector(X_test,new_vocab,term_count)"
      ],
      "metadata": {
        "id": "73RjTAhjN5fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector=TfidfTransformer()\n",
        "x_train=vector.fit_transform(x_train)\n",
        "x_test=vector.transform(x_test)"
      ],
      "metadata": {
        "id": "3aka-dtrN-pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "LnYdDpHyHF_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "kernels = ['Polynomial', 'RBF', 'Sigmoid','Linear']#A function which returns the corresponding SVC model\n",
        "def getClassifier(ktype):\n",
        "    if ktype == 0:\n",
        "        # Polynomial kernal\n",
        "        return SVC(kernel='poly', degree=8, gamma=\"auto\")\n",
        "    elif ktype == 1:\n",
        "        # Radial Basis Function kernal\n",
        "        return SVC(kernel='rbf', gamma=\"auto\")\n",
        "    elif ktype == 2:\n",
        "        # Sigmoid kernal\n",
        "        return SVC(kernel='sigmoid', gamma=\"auto\")\n",
        "    elif ktype == 3:\n",
        "        # Linear kernal\n",
        "        return SVC(kernel='linear', gamma=\"auto\")"
      ],
      "metadata": {
        "id": "lPj0DK_yHFGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(4):\n",
        "    svclassifier = getClassifier(i) \n",
        "    svclassifier.fit(x_train, Y_train)# Make prediction\n",
        "    y_pred = svclassifier.predict(x_test)# Evaluate our model\n",
        "    print(\"Evaluation:\", kernels[i], \"kernel\")\n",
        "    print(classification_report(Y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gONpJVIHHKHi",
        "outputId": "829c483a-f3c9-41d6-d12b-dcb60f50a372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation: Polynomial kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AAP       0.00      0.00      0.00        22\n",
            "         BJP       0.00      0.00      0.00        72\n",
            "    CONGRESS       0.00      0.00      0.00        48\n",
            "        NONE       0.37      1.00      0.54        83\n",
            "\n",
            "    accuracy                           0.37       225\n",
            "   macro avg       0.09      0.25      0.13       225\n",
            "weighted avg       0.14      0.37      0.20       225\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation: RBF kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AAP       0.00      0.00      0.00        22\n",
            "         BJP       0.00      0.00      0.00        72\n",
            "    CONGRESS       0.00      0.00      0.00        48\n",
            "        NONE       0.37      1.00      0.54        83\n",
            "\n",
            "    accuracy                           0.37       225\n",
            "   macro avg       0.09      0.25      0.13       225\n",
            "weighted avg       0.14      0.37      0.20       225\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation: Sigmoid kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AAP       0.00      0.00      0.00        22\n",
            "         BJP       0.00      0.00      0.00        72\n",
            "    CONGRESS       0.00      0.00      0.00        48\n",
            "        NONE       0.37      1.00      0.54        83\n",
            "\n",
            "    accuracy                           0.37       225\n",
            "   macro avg       0.09      0.25      0.13       225\n",
            "weighted avg       0.14      0.37      0.20       225\n",
            "\n",
            "Evaluation: Linear kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AAP       0.95      0.95      0.95        22\n",
            "         BJP       0.79      0.89      0.84        72\n",
            "    CONGRESS       0.90      0.79      0.84        48\n",
            "        NONE       0.90      0.87      0.88        83\n",
            "\n",
            "    accuracy                           0.87       225\n",
            "   macro avg       0.89      0.88      0.88       225\n",
            "weighted avg       0.87      0.87      0.87       225\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classifier Algorithm**"
      ],
      "metadata": {
        "id": "Dvk74afaHZ5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "def run_classifier(clf, param_grid, title):\n",
        "    # -----------------------------------------------------\n",
        "    cv = StratifiedKFold(n_splits= 3, shuffle = True, random_state= 123)\n",
        "    # Randomized grid search\n",
        "    n_iter_search = 10\n",
        "    gs = RandomizedSearchCV(clf, \n",
        "                            param_distributions = param_grid,\n",
        "                            n_iter = n_iter_search, \n",
        "                            cv = cv,                 \n",
        "                            scoring= 'accuracy')\n",
        "    # -----------------------------------------------------\n",
        "    # Train model\n",
        "    gs.fit(x_train, Y_train)  \n",
        "    print(\"The best parameters are %s\" % (gs.best_params_)) \n",
        "    # Predict on test set\n",
        "    y_pred = gs.best_estimator_.predict(x_test)\n",
        "    # Get Probability estimates\n",
        "    y_prob = gs.best_estimator_.predict_proba(x_test)[:, 1]\n",
        "    # -----------------------------------------------------\n",
        "    print('Accuracy score: %.2f%%' %(accuracy_score(Y_test, y_pred)*100))  \n",
        "    print('Precision score: %.2f%%' % (precision_score(Y_test, y_pred, average= 'weighted')*100))\n",
        "    print('Recall score: %.2f%%' % (recall_score(Y_test, y_pred, average= 'weighted')*100))"
      ],
      "metadata": {
        "id": "SUtJDJUPGpeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logisitic Regression**"
      ],
      "metadata": {
        "id": "w1bABG8fHflX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "param_grid = {'penalty': ['l2'],\n",
        "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "run_classifier(lr, param_grid, 'Logistic Regression')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0ed3U6SGzW3",
        "outputId": "5a822ff3-38e2-4bf1-f31f-7b633ecfed78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'solver': 'saga', 'penalty': 'l2'}\n",
            "Accuracy score: 83.11%\n",
            "Precision score: 83.75%\n",
            "Recall score: 83.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "W716xniCHrzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zqNvuAAYHo7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "param_grid = {'n_neighbors': np.arange(1,15), \n",
        "             'weights': ['uniform', 'distance'],\n",
        "             'leaf_size':[1, 3, 5],\n",
        "             'algorithm':['auto', 'kd_tree']}\n",
        "run_classifier(knn, param_grid, 'Nearest Neighbors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqxBt0XDHkmZ",
        "outputId": "8e6e4f65-137d-4fe7-da49-885823cf6f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'weights': 'distance', 'n_neighbors': 4, 'leaf_size': 3, 'algorithm': 'auto'}\n",
            "Accuracy score: 75.11%\n",
            "Precision score: 75.44%\n",
            "Recall score: 75.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "c34KMOA9H1g5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rWhZGP3OHvAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree = DecisionTreeClassifier()\n",
        "param_grid = {'criterion': ['gini', 'entropy'],\n",
        "              'splitter': ['best', 'random'],\n",
        "              'max_depth': np.arange(1, 20, 2),\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 2, 4, 10],\n",
        "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
        "run_classifier(dtree, param_grid, \"Decision Tree\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD5VJhAkHz1t",
        "outputId": "cea28a14-b1ad-4d48-e0b5-c9d076031625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'splitter': 'random', 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 13, 'criterion': 'gini'}\n",
            "Accuracy score: 79.11%\n",
            "Precision score: 79.00%\n",
            "Recall score: 79.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "S8LxosP_IGyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "param_grid = {'n_estimators': [100, 200],\n",
        "              'max_depth': [10, 20, 100, None],\n",
        "              'max_features': ['auto', 'sqrt', None],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 2, 4, 10],\n",
        "              'bootstrap': [True, False],\n",
        "              'criterion': ['gini', 'entropy']}\n",
        "run_classifier(rf, param_grid, 'Random Forest')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5PeithsIKbI",
        "outputId": "efdb3e3b-5390-483b-9f6b-cc06c76465d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 100, 'criterion': 'gini', 'bootstrap': True}\n",
            "Accuracy score: 89.33%\n",
            "Precision score: 89.77%\n",
            "Recall score: 89.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest - One Vs All MultiClass Classifier**"
      ],
      "metadata": {
        "id": "yypneWBkIYSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "model =RandomForestClassifier(n_estimators= 200, min_samples_split= 2, min_samples_leaf= 1, max_features= 'sqrt', max_depth= 100, criterion= 'gini', bootstrap= True)\n",
        "ovr = OneVsRestClassifier(model)\n",
        "ovr.fit(x_train, Y_train)\n",
        "y_pred = ovr.predict(x_test)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "print(\"Confusion Matrix : \\n\", cm)\n",
        "print('Accuracy score: %.2f%%' %(accuracy_score(Y_test, y_pred)*100))  \n",
        "print('Precision score: %.2f%%' % (precision_score(Y_test, y_pred, average= 'weighted')*100))\n",
        "print('Recall score: %.2f%%' % (recall_score(Y_test, y_pred, average= 'weighted')*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb-MPkV-IP32",
        "outputId": "7a21fd8e-aaf4-4f33-aef5-45837bbf797f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            " [[22  0  0  0]\n",
            " [ 0 66  3  3]\n",
            " [ 0  5 41  2]\n",
            " [ 0  7  1 75]]\n",
            "Accuracy score: 90.67%\n",
            "Precision score: 90.88%\n",
            "Recall score: 90.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dumping the Model**"
      ],
      "metadata": {
        "id": "xOjvGi7nPHtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = '/content/drive/MyDrive/IR PROJECT/RFC_OneVsAll.sav'\n",
        "pickle.dump(ovr, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "fNc4YvwqO_D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest - One Vs One MultiClass Classifier**"
      ],
      "metadata": {
        "id": "MoRyAdnbJ-I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "model =RandomForestClassifier(n_estimators= 200, min_samples_split= 2, min_samples_leaf= 1, max_features='sqrt', max_depth= 100, criterion= 'gini', bootstrap= True)\n",
        "ovo = OneVsOneClassifier(model)\n",
        "ovo.fit(x_train, Y_train)\n",
        "y_pred = ovo.predict(x_test)\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "print(\"Confusion Matrix : \\n\", cm)\n",
        "print('Accuracy score: %.2f%%' %(accuracy_score(Y_test, y_pred)*100))  \n",
        "print('Precision score: %.2f%%' % (precision_score(Y_test, y_pred, average= 'weighted')*100))\n",
        "print('Recall score: %.2f%%' % (recall_score(Y_test, y_pred, average= 'weighted')*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3S7DGARKFWq",
        "outputId": "5f134950-55af-4aaf-d084-ff0110786454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            " [[22  0  0  0]\n",
            " [ 0 67  2  3]\n",
            " [ 0  5 40  3]\n",
            " [ 0  8  1 74]]\n",
            "Accuracy score: 90.22%\n",
            "Precision score: 90.54%\n",
            "Recall score: 90.22%\n"
          ]
        }
      ]
    }
  ]
}